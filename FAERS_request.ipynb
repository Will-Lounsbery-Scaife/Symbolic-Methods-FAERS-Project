{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import copy\n",
    "\n",
    "# are we using AEOLUS or FAERS_standard?\n",
    "aeolus = 0\n",
    "FAERS_std = 1\n",
    "\n",
    "\n",
    "# rate limiting is important to avoid accidental service abuse of the OpenFDA API provider\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "\n",
    "# cache API calls in a sqllite file to reduce the number of requests to openfda server\n",
    "import requests_cache\n",
    "requests_cache.install_cache('openfda_cache')\n",
    "\n",
    "OPENFDA_API = \"https://api.fda.gov/drug/event.json\"\n",
    "\n",
    "@sleep_and_retry\n",
    "@limits(calls=40, period=60)\n",
    "def call_api(params):\n",
    "    \"\"\"\n",
    "    OpenFDA API call. Respects rate limit. Overrides default data limit\n",
    "    Input: dictionary with API parameters {search: '...', count: '...'}\n",
    "    Output: nested dictionary representation of the JSON results section\n",
    "    \n",
    "    OpenFDA API rate limits:\n",
    "         With no API key: 40 requests per minute, per IP address. 1000 requests per day, per IP address.\n",
    "         With an API key: 240 requests per minute, per key. 120000 requests per day, per key.\n",
    "    \"\"\"\n",
    "    if not params:\n",
    "        params = {}\n",
    "    params['limit'] = params.get('limit', 1000)\n",
    "    response = requests.get(OPENFDA_API, params=params)\n",
    "    \n",
    "    print(response.url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('API response: {}'.format(response.status_code))\n",
    "    return response.json()['results']\n",
    "\n",
    "OPENFDA_METADATA_YAML = \"https://open.fda.gov/fields/drugevent.yaml\"\n",
    "# munch is a yaml parser with javascript-style object access\n",
    "from munch import Munch\n",
    "\n",
    "def api_meta():\n",
    "    \"\"\"\n",
    "    YAML file with field description and other metadata retrieved from the OpenFDA website\n",
    "    Parses YAML file and provides syntactic sugar for accessing nested dictionaries\n",
    "    Example: .patient.properties.patientagegroup.possible_values.value\n",
    "    Note: reserved words, such as count and items still have to be accessed via ['count'], ['items']\n",
    "    \"\"\"\n",
    "    response = requests.get(OPENFDA_METADATA_YAML)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Could not retrieve YAML file with drug event API fields')\n",
    "    y = Munch.fromYAML(response.text)\n",
    "    return y['properties']\n",
    "\n",
    "# API key that I got from FAERS site\n",
    "columbia_api_key = 'Og4jAa0KIhPJkiwaxXVD6VHp3DGqoQf37JFPeRct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20110701', '20110702', '20110703', '20110704']\n"
     ]
    }
   ],
   "source": [
    "start_date = '20110701'\n",
    "end_date = '20110704'\n",
    "\n",
    "#start_date = input(\"Enter the beginning of your desired date range (YYMMDDDD): \" )\n",
    "#end_date = input(\"Enter the end of your desired date range (YYMMDDDD): \")\n",
    "\n",
    "#country_list = input(\"Enter the countries you would like to limit your search to: \")\n",
    "country_list = [\"FR\", \"DE\", \"ES\", \"IT\",\"CH\"]\n",
    "\n",
    "# reformat the dates to match FAERS\n",
    "def get_dates(strt_dt, end_dt):\n",
    "    # create a range of all dates between start and end date\n",
    "    my_range = pd.date_range(start=strt_dt, end=end_dt)\n",
    "    f_range = []\n",
    "    for dt in my_range:\n",
    "        y = str(dt)[0:4]\n",
    "        m = str(dt)[5:7]\n",
    "        d = str(dt)[8:10]\n",
    "        new_dt = y + m + d\n",
    "        f_range.append(new_dt)\n",
    "    return f_range\n",
    "\n",
    "# list of dates to limit search to\n",
    "date_range = get_dates(start_date, end_date)\n",
    "print(date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.fda.gov/drug/event.json?limit=5&api_key=Og4jAa0KIhPJkiwaxXVD6VHp3DGqoQf37JFPeRct&search=transmissiondate%3A%5B20040101+TO+20150630%5D+AND+patient.reaction.reactionmeddrapt%3A%28%22Heat+exhaustion%22+OR+%22Heat+stroke%22%29\n"
     ]
    }
   ],
   "source": [
    "# strings that go in the URL of the API query\n",
    "\n",
    "\n",
    "# test strings for API query search fields\n",
    "date_query = 'patient.summary.narrativeincludeclinical:('\n",
    "d_sub = '\"CASE EVENT DATE:'\n",
    "\n",
    "# add each date in range to date_query\n",
    "date_ind = 0\n",
    "num_dates = len(date_range)\n",
    "for ymd in date_range:\n",
    "    date_ind += 1\n",
    "    if date_ind < num_dates:\n",
    "        date_query += d_sub + ymd + '\"' + \" OR \"\n",
    "    else:\n",
    "        date_query += d_sub + ymd + '\"' + \")\"\n",
    "\n",
    "\n",
    "# potential search query terms to add to API query\n",
    "#country_query = 'primarysource.reportercountry:\"FR\"'\n",
    "#country_query = '(primarysource.reportercountry:\"FR\" OR occurcountry:\"FR\" OR primarysourcecountry:\"FR\")'\n",
    "#country_query = 'primarysource.reportercountry:(\"FR\" OR \"DE\" OR \"ES\" OR \"IT\" OR \"CH\")'\n",
    "country_query = 'occurcountry:(\"FR\" OR \"DE\" OR \"ES\" OR \"IT\" OR \"CH\")'\n",
    "reaction_query = 'patient.reaction.reactionmeddrapt:(\"Heat exhaustion\" OR \"Heat stroke\")'\n",
    "\n",
    "# get an api response with the given search query terms\n",
    "test_out = call_api({\n",
    "    'limit': 5,\n",
    "    'api_key': columbia_api_key,\n",
    "    'search': 'transmissiondate:[20040101 TO 20150630]' + ' AND ' + reaction_query\n",
    "    #'search': 'transmissiondate:[20040101 TO 20150630]' + ' AND ' + country_query + ' AND ' + date_query\n",
    "    #'search': 'transmissiondate:[20150630 TO 20150730]' + ' AND ' + country_query\n",
    "    #'search': country_query + ' AND ' + date_query\n",
    "    #'search': 'safetyreportid:10332098'\n",
    "\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list to store all case IDs\n",
    "safetyreportid_list = []\n",
    "\n",
    "# iterate through each entry, store safetyreportid\n",
    "def get_safetyreportids(api_results):\n",
    "    write_obj = open('results.txt', 'w')\n",
    "    write_obj.close()\n",
    "    results_obj = open('results.txt', 'a')\n",
    "    for entry in api_results:\n",
    "        # safetyreportid\n",
    "        results_obj.write(\"report ID: \")\n",
    "        results_obj.write(str(entry['safetyreportid']) + \"\\n\")\n",
    "        safetyreportid_list.append(str(entry['safetyreportid']))\n",
    "\n",
    "        # reportercountry\n",
    "        results_obj.write(\"\\treportercountry: \" + str(entry['primarysource']['reportercountry']) + \"\\n\")\n",
    "\n",
    "        # sex\n",
    "        if 'patientsex' in entry['patient']:\n",
    "            results_obj.write(\"\\tsex: \" + str(entry['patient']['patientsex']) + \"\\n\")\n",
    "\n",
    "        # date\n",
    "        if 'summary' in entry['patient']:\n",
    "            results_obj.write(\"\\t\" + str(entry['patient']['summary']['narrativeincludeclinical']) + \"\\n\")\n",
    "    results_obj.close()\n",
    "\n",
    "    \n",
    "get_safetyreportids(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary templates\n",
    "\n",
    "\n",
    "# template for KEGG value\n",
    "KEGG_template = {\"get_URL\": None, \"D_number\": None, \"Classes\": [], \"Target\": [ ], \"Pathway\": None }  \n",
    "\n",
    "if aeolus == 1:\n",
    "    # template for a drug value\n",
    "    drug_template = { \"drug_concept_id\": None, \"drug_name\": None, \"role_cod\": None, \"KEGG\": KEGG_template.copy()}\n",
    "\n",
    "    # template for a primaryid value\n",
    "    pid_template = {'reactions_SNOMED': [], 'reactions_MedDRA': [], 'drugs': []}\n",
    "\n",
    "if FAERS_std == 1:\n",
    "    # template for a drug value\n",
    "    drug_template = { \"drug_concept_id\": None, \"drug_name\": None, \"role_cod\": None, \"KEGG\": KEGG_template.copy()}\n",
    "\n",
    "    # template for a primaryid value\n",
    "    pid_template = { 'reactions_MedDRA': None, 'drugs': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get lines in given file that match certain strings\n",
    "# used to search standard_case_drug, standard_case_outcome.tsv, or RxNorm CONCEPT.csv\n",
    "def AEOLUS_generate_lines_that_equal(string, fp, case):\n",
    "    # iterate through each line in the given file\n",
    "    yielded = set() # for ensuring only non-duplicate drug concepts ids are yielded\n",
    "    for line in fp:\n",
    "        # if there is a match\n",
    "        if line.startswith(string):\n",
    "            # split line by tabs\n",
    "            line_2 = line.strip(\"\\n\")\n",
    "            tab_split = line_2.split('\\t')\n",
    "            # get the last column (concept id) and second to last column (role_cod)\n",
    "            # non-duplicate drug concepts\n",
    "            if case == 0:\n",
    "                return_col0 = tab_split[(len(tab_split)-1)]\n",
    "                # role_cod\n",
    "                return_col1 = tab_split[3]\n",
    "                # ensure no duplicates\n",
    "                if tuple([return_col0, return_col1]) in yielded:\n",
    "                    continue\n",
    "                yield [return_col0, return_col1]\n",
    "                yielded.add(tuple([return_col0, return_col1]))\n",
    "            # RxNorm drug names\n",
    "            elif case == 1:\n",
    "                return_col0 = tab_split[1]\n",
    "                yield return_col0\n",
    "            # SNOMED and MedDRA pt outcome concepts from standard_case_outcome\n",
    "            elif case == 2:\n",
    "                # SNOMED code\n",
    "                return_col0 = tab_split[(len(tab_split)-1)]\n",
    "                # MedDRA pt\n",
    "                return_col1 = tab_split[2]\n",
    "                yield [return_col0, return_col1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds a drug subdictionary for each drug for each corresponding safetyreportid key in AEOLUS\n",
    "def add_AEOLUS_data_to_dictionary():\n",
    "    # creates a dictionary entry for each id\n",
    "    res_dict = dict( (pid, pid_template.copy()) for pid in safetyreportid_list )\n",
    "    print(res_dict)\n",
    "    # search standard_case_drug.tsv for each safetyreportid key\n",
    "    # adds drug subdictionary for each drug for each report\n",
    "    with open(\"doi_10.5061_dryad.8q0s4__v1/aeolus_v1/standard_case_drug.tsv\", \"r\") as fp:\n",
    "        for pid in res_dict:\n",
    "            # generate a list of drug_ids associated with each safetyreportID\n",
    "            for i in AEOLUS_generate_lines_that_equal(str(pid), fp, 0):\n",
    "                template_copy = copy.deepcopy(drug_template)\n",
    "                # assign drug_concept_ids\n",
    "                template_copy['drug_concept_id'] = i[0]\n",
    "                # assign role_cod (primary suspect, secondary suspect, concomitant, etc)\n",
    "                template_copy['role_cod'] = i[1]\n",
    "                drugs_sub_dict_copy = copy.deepcopy(res_dict[pid]['drugs'])\n",
    "                drugs_sub_dict_copy.append(template_copy)\n",
    "                res_dict[pid]['drugs'] = drugs_sub_dict_copy\n",
    "            # go back to first line\n",
    "            fp.seek(0)\n",
    "    # adds outcome for each safetyreportid key by searching standard_case_outcome file\n",
    "    with open(\"doi_10.5061_dryad.8q0s4__v1/aeolus_v1/standard_case_outcome.tsv\") as fp:\n",
    "        for pid in res_dict:\n",
    "            # generate a list of MedDRA reactions and SNOMED reactions associated with each safetyreportID\n",
    "            count = 1\n",
    "            for i in AEOLUS_generate_lines_that_equal(str(pid), fp, 2):\n",
    "                SNOMED_react_copy = res_dict[pid]['reactions_SNOMED'].copy()\n",
    "                MedDRA_react_copy = res_dict[pid]['reactions_MedDRA'].copy()\n",
    "                SNOMED_react_copy.append(i[0])\n",
    "                MedDRA_react_copy.append(i[1])\n",
    "                res_dict[pid]['reactions_SNOMED'] = SNOMED_react_copy\n",
    "                res_dict[pid]['reactions_MedDRA'] = MedDRA_react_copy\n",
    "            # go back to first line\n",
    "            fp.seek(0)\n",
    "    # adds drug names from RxNorm by searching drug concept IDs\n",
    "    with open(\"RxNorm_vocab/CONCEPT.csv\", \"r\") as fp:\n",
    "        # adds drug names from RxNorm by searching drug concept IDs\n",
    "        for pid in res_dict:\n",
    "            for drug in res_dict[pid]['drugs']:\n",
    "                d_id = drug['drug_concept_id']\n",
    "                drug_name_vals = []\n",
    "                # search standard_case_drug for ids\n",
    "                for i in AEOLUS_generate_lines_that_equal(d_id, fp, 1):\n",
    "                    drug_name_vals.append(i)\n",
    "                    drug['drug_name'] = i\n",
    "                # go back to first line\n",
    "                fp.seek(0)\n",
    "    return(res_dict)\n",
    "\n",
    "    \n",
    "if aeolus == 1:\n",
    "    results_dict = add_AEOLUS_data_to_dictionary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "#caseid, primaryid, caseversion, fda_dt, I_F_COD, event_dtm, AGE, Gender, COUNTRY_CODE, Period\n",
    "\n",
    "# useful Linux commands:\n",
    "# grep 10151788 DRUGS_STANDARDIZED.txt | awk '$1 ~ /10151788/ {print $0}'\n",
    "# grep rivaroxaban CONCEPT.csv | awk '$5==\"Ingredient\" {print $0}'\n",
    "\n",
    "# TODO: implement way to search for reactions in a date range (SQL?)\n",
    "# TODO: get the SQL tables to work in general...\n",
    "\n",
    "# get primaryids in FAERS_stand files in given date\n",
    "# used to search DEMOGRAPHICS.txt\n",
    "def FAERS_standard_generate_primaryids(fp, case):\n",
    "    # iterate through each line in the given file\n",
    "    # case: search DEMOGRAPHICS.txt for matching dates AND countries\n",
    "    if case == 1:\n",
    "        for line in fp:\n",
    "            split_line = line.split(\"$\")\n",
    "            if split_line[5] in date_range and split_line[8] in country_list:\n",
    "                # store primaryid, country, age, gender, date\n",
    "                primaryid = split_line[1]\n",
    "                #country_abbr = split_line[8]\n",
    "                #age = split_line[6]\n",
    "                #gender = split_line[7]\n",
    "                #event_dt = split_line[5]\n",
    "                #yield [primaryid, country_abbr, age, gender, event_dt]\n",
    "                yield primaryid\n",
    "\n",
    "# generate drug info associated with each primaryid\n",
    "def FAERS_standard_generate_drugs(string, fp):\n",
    "    # primaryid, DRUG_ID, DRUG_SEQ, ROLE_COD, PERIOD, RXAUI, DRUG\n",
    "    for line in fp:\n",
    "        split_line = line.split(\"$\")\n",
    "        if split_line[0] == string:\n",
    "            # store drug's name, id, role\n",
    "            drug_name = split_line[6].replace(\"\\n\", \"\")\n",
    "            drug_id = split_line[1]\n",
    "            drug_role = split_line[3]\n",
    "            yield [drug_name, drug_id, drug_role]\n",
    "    # case: search RxNorm for drug names/ingredient\n",
    "\n",
    "# generate reactions associated with each primaryid\n",
    "def FAERS_standard_generate_reactions(string, fp):\n",
    "    for line in fp:\n",
    "        split_line = line.split(\"$\")\n",
    "        if split_line[0] == string:\n",
    "            yield split_line[2].replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20190623', '20190624', '20190625', '20190626', '20190627', '20190628']\n",
      "1036\n"
     ]
    }
   ],
   "source": [
    "# European heat waves, June 2019\n",
    "# start = 20190623\n",
    "# end = 20190628 \n",
    "# countries =  Belgium, France, Germany, Poland, the Netherlands, Spain, Switzerland, and the United Kingdom\n",
    "# country_list = [\"BE\", \"FR\", \"DE\", \"NL\", \"GB\", \"PL\", \"ES\", \"CH\"]\n",
    "import datetime\n",
    "if FAERS_std == 1:\n",
    "    #date_range = get_dates('20190623', '20190628')\n",
    "    #date_range = get_dates('20110702', '20110703')\n",
    "    start_date = datetime.date(2019, 6, 23)\n",
    "    end_date = datetime.date(2022, 6, 28)\n",
    "    date_range = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        date_range.append(current_date)\n",
    "        current_date += datetime.timedelta(days=1)\n",
    "    \n",
    "\n",
    "    \n",
    "    #country_list = [\"FR\", \"DE\", \"ES\", \"IT\",\"CH\"]\n",
    "    #country_list = [\"FR\"]\n",
    "    country_list = [\"BE\", \"FR\", \"DE\", \"NL\", \"GB\", \"PL\", \"ES\", \"CH\"]\n",
    "\n",
    "\n",
    "# adds a drug subdictionary for each drug for each corresponding safetyreportid key in FAERS_standardized\n",
    "def add_FAERS_standard_data_to_dictionary():\n",
    "\n",
    "    # add primaryid keys that fulfill the search criteria\n",
    "    with open(\"FAERS_standardized/DEMOGRAPHICS.txt\", \"r\") as fp:\n",
    "        # generate a list of demographic info for each primaryid that fulfills the search requirements\n",
    "        get_entries = FAERS_standard_generate_primaryids(fp, 1)\n",
    "        primaryid_list = []\n",
    "        # extract primaryids from the entries of interest\n",
    "        for match_line in get_entries:\n",
    "            primaryid_list.append(match_line)\n",
    "    res_dict_2 = dict( (pid, pid_template.copy()) for pid in primaryid_list )\n",
    "    print(len(primaryid_list))\n",
    "\n",
    "    # generate list of drugs associated with each primaryid\n",
    "    with open(\"FAERS_standardized/DRUGS_STANDARDIZED.txt\", \"r\") as fp:\n",
    "        results_copy = copy.deepcopy(res_dict_2)\n",
    "        # add info for each pid\n",
    "        for pid in results_copy:\n",
    "            drugs_copy = copy.deepcopy(results_copy[pid]['drugs'])\n",
    "            # add info for each drug in a given pid\n",
    "            for i in FAERS_standard_generate_drugs(pid, fp):\n",
    "                drugs_sub_dict_copy = copy.deepcopy(drug_template)\n",
    "                # assign drug_names\n",
    "                drugs_sub_dict_copy['drug_name'] = i[0]\n",
    "\n",
    "                # assign drug_concept_ids\n",
    "                drugs_sub_dict_copy['drug_concept_id'] = i[1]\n",
    "\n",
    "                # assign role_cod (primary suspect, secondary suspect, concomitant, etc)\n",
    "                drugs_sub_dict_copy['role_cod'] = i[2]\n",
    "                \n",
    "                drugs_copy.append(drugs_sub_dict_copy)\n",
    "            results_copy[pid]['drugs'] = drugs_copy\n",
    "            # go back to first line\n",
    "            fp.seek(0)\n",
    "\n",
    "    \n",
    "    # adds outcome for each primary key by searching ADVERSE_REACTIONS.txt\n",
    "    with open(\"FAERS_standardized/ADVERSE_REACTIONS.txt\") as fp:\n",
    "        for pid in results_copy:\n",
    "            reactions_list = []\n",
    "            # generate a list reactions for each primaryid\n",
    "            for i in FAERS_standard_generate_reactions(pid, fp):\n",
    "                reactions_list.append(i)\n",
    "                results_copy[pid]['reactions_MedDRA'] = reactions_list\n",
    "            fp.seek(0)\n",
    "    res_dict_2 = results_copy\n",
    "    return(res_dict_2)\n",
    "\n",
    "\n",
    "if FAERS_std == 1:\n",
    "    results_dict = add_FAERS_standard_data_to_dictionary()\n",
    "    #for pid in results_dict:\n",
    "    #    print(\"\\n\", pid, results_dict[pid])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEGG_find_base = 'https://rest.kegg.jp/find/drug/'\n",
    "KEGG_get_base = 'https://rest.kegg.jp/get/'\n",
    "\n",
    "poss1 = 0\n",
    "# function to generate the appropriate URLs for KEGG API queries\n",
    "# uses the find request to search a drug string, then determines the d-number of the drug for the get-url \n",
    "def KEGG_find_query(drug_string):\n",
    "    poss1 = 0\n",
    "    find_url = KEGG_find_base + drug_string\n",
    "    find_req = requests.get(find_url)\n",
    "    a = find_req.text.split(\"\\n\")\n",
    "    b = []\n",
    "    for l in a:\n",
    "        b.append(l.split(\"\\t\"))\n",
    "    b.pop()\n",
    "    # iterate through find entries to find INN names, extract the d number\n",
    "    # if multiple entries contain INN, store the first one with matching start\n",
    "    for found_entry in b:\n",
    "        #print(\"here1\", found_entry[1].lower())\n",
    "        #print(\"here2\", drug_string)\n",
    "\n",
    "        if \"INN\" in found_entry[1] and found_entry[1].lower().startswith(drug_string.lower()):\n",
    "            #print(\"case1\", found_entry)\n",
    "            get_url = KEGG_get_base + found_entry[0]\n",
    "            x = found_entry[0].split(\":\")\n",
    "            #print(x)\n",
    "            d_number = x[1]\n",
    "            #print(d_number)\n",
    "            # put d number at end of get URL\n",
    "            return [find_url, get_url, d_number]\n",
    "\n",
    "    for found_entry in b:\n",
    "        if \"INN\" in found_entry[1]:\n",
    "            #print(\"case2\", found_entry)\n",
    "            get_url = KEGG_get_base + found_entry[0]\n",
    "            x = found_entry[0].split(\":\")\n",
    "            #print(x)\n",
    "            d_number = x[1]\n",
    "            #print(d_number)\n",
    "            # put d number at end of get URL\n",
    "            #return [find_url, get_url, d_number]\n",
    "            poss1 = [find_url, get_url, d_number]\n",
    "            break\n",
    "    # if no \"INN\" entries found, store first that has drug name not preceded by non-whitespace chars\n",
    "    for found_entry in b:\n",
    "        if found_entry[1].lower().startswith(drug_string.lower()):\n",
    "            d_number = found_entry[0].split(\":\")[1]\n",
    "            #print(\"case3\")\n",
    "            if poss1 == 0:\n",
    "                #print(\"chose\", [find_url, KEGG_get_base + b[0][0], d_number], \"over\", poss1 )\n",
    "                return [find_url, KEGG_get_base + b[0][0], d_number]\n",
    "            else: \n",
    "                return poss1\n",
    "    #for found_entry in b:\n",
    "    # otherwise, just store first entry\n",
    "    #if poss1: return poss1\n",
    "    #print(\"otherwise\", drug_string, b[0][0].split(\":\")[1])\n",
    "    return [find_url, KEGG_get_base + b[0][0], b[0][0].split(\":\")[1]]\n",
    "    \n",
    "#print(KEGG_find_query('potassium citrate'))\n",
    "#print(KEGG_find_query('estriol'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to Kegg and store drug targets, pathway, and class\n",
    "def KEGG_get_query(get_URL):\n",
    "    \n",
    "    target = []\n",
    "    pathway = []\n",
    "    class_info = []\n",
    "    get_req = requests.get(get_URL)\n",
    "    klines = get_req.iter_lines()\n",
    "    # booleans to keep track of if a line stores info on pathway, class, or target\n",
    "    is_targ = 0\n",
    "    is_path = 0\n",
    "    is_class = 0\n",
    "    # iterate through get response\n",
    "    for line in klines:\n",
    "        dec = line.decode(\"utf-8\")\n",
    "        # line has class info\n",
    "        if dec.startswith(\"CLASS\"):\n",
    "            is_class = 1\n",
    "        # line does not have class info\n",
    "        if dec.startswith(\"REMARK\"):\n",
    "            is_class = 0\n",
    "        # line has target info\n",
    "        if dec.startswith(\"TARGET\"):\n",
    "            is_targ = 1\n",
    "        # line has pathway info, not target info\n",
    "        if dec[2:9]==\"PATHWAY\":\n",
    "            is_path = 1\n",
    "            is_targ = 0\n",
    "        # line no longer has path info\n",
    "        if dec.startswith(\"INTERACTION\"):\n",
    "            is_targ = 0\n",
    "            is_path = 0\n",
    "        # if the line corresponds to a field of interest, store it\n",
    "        if is_class == 1: \n",
    "            #print(dec)\n",
    "            # gets the name and dg-number of the most specific KEGG drug groups associated with the given d-number\n",
    "            class_info.append(dec[12:])\n",
    "        elif is_targ == 1: target.append(dec[12:])\n",
    "        elif is_path == 1: pathway.append(dec[12:])\n",
    "    # store most specific drug groups\n",
    "    class_list = []\n",
    "    for ind in range(len(class_info)):\n",
    "        # add last class line by default\n",
    "        if ind == len(class_info) - 1:\n",
    "            split_line = class_info[ind].strip(\" \").split(\"  \")\n",
    "            #print(split_line)\n",
    "            class_list.append([split_line[0], split_line[1]])\n",
    "            break\n",
    "        if \" DG\" in class_info[ind]:\n",
    "            # not the most specific drug group; continue to next line\n",
    "            if \" DG\" in class_info[ind+1]: continue\n",
    "            else: \n",
    "                split_line = class_info[ind].strip(\" \").split(\"  \")\n",
    "                class_list.append([split_line[0], split_line[1]])\n",
    "    #print(\"\\n\", class_list)\n",
    "    return(target, pathway, class_list)\n",
    "\n",
    "#print(KEGG_get_query('https://rest.kegg.jp/get/dr:D05212'))\n",
    "#print(KEGG_get_query('https://rest.kegg.jp/get/dr:D07784'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No KEGG: pirinitramide \n",
      "\n",
      "No KEGG: placebo \n",
      "\n",
      "No KEGG: Saccharomyces boulardii \n",
      "\n",
      "No KEGG: heavy mineral oil \n",
      "\n",
      "No KEGG: estriol \n",
      "\n",
      "No KEGG: placebo \n",
      "\n",
      "No KEGG: placebo \n",
      "\n",
      "No KEGG: placebo \n",
      "\n",
      "No KEGG: placebo \n",
      "\n",
      "No KEGG: ELECTROLYTES \n",
      "\n",
      "No KEGG: magnesium lactate \n",
      "\n",
      "No KEGG: acellular pertussis vaccine, inactivated \n",
      "\n",
      "No KEGG: diphtheria toxoid vaccine, inactivated \n",
      "\n",
      "No KEGG: tetanus toxoid vaccine, inactivated \n",
      "\n",
      "No KEGG: anethole trithione \n",
      "\n",
      "No KEGG: follicle stimulating hormone \n",
      "\n",
      "No KEGG: protease \n",
      "\n",
      "No KEGG: hepatitis B virus subtype ADW2 HBsAg surface protein antigen \n",
      "\n",
      "No KEGG: Haemophilus influenzae type b, capsular polysaccharide inactivated tetanus toxoid conjugate vaccine \n",
      "\n",
      "No KEGG: protease \n",
      "\n",
      "No KEGG: C1 esterase inhibitor \n",
      "\n",
      "No KEGG: C1 esterase inhibitor \n",
      "\n",
      "No KEGG: protease \n",
      "\n",
      "No KEGG: sodium ironedetate \n",
      "\n",
      "No KEGG: Saccharomyces cerevisiae \n",
      "\n",
      "No KEGG: S-benzoylmercaptoacetyltriglycine \n",
      "\n",
      "No KEGG: S-benzoylmercaptoacetyltriglycine \n",
      "\n",
      "No KEGG: technetium Tc 99m pertechnetate \n",
      "\n",
      "No KEGG: technetium Tc 99m pertechnetate \n",
      "\n",
      "No KEGG: herbal drugs \n",
      "\n",
      "No KEGG: Insulin beef \n",
      "\n",
      "No KEGG: Delorazepam \n",
      "\n",
      "No KEGG: picosulfurate \n",
      "\n",
      "No KEGG: placebo \n",
      "\n",
      "No KEGG: placebo \n",
      "\n",
      "No KEGG: protease \n",
      "\n",
      "No KEGG: Haemophilus influenzae type b, capsular polysaccharide inactivated tetanus toxoid conjugate vaccine \n",
      "\n",
      "No KEGG: hepatitis B virus subtype ADW2 HBsAg surface protein antigen \n",
      "\n",
      "No KEGG: heavy mineral oil \n",
      "\n",
      "No KEGG: ELECTROLYTES \n",
      "\n",
      "No KEGG: Saccharomyces boulardii \n",
      "\n",
      "No KEGG: follicle stimulating hormone \n",
      "\n",
      "No KEGG: L1 protein, human papillomavirus type 18 vaccine \n",
      "\n",
      "No KEGG: L1 protein, human papillomavirus type 16 vaccine \n",
      "\n",
      "No KEGG: ispaghula extract \n",
      "\n",
      "No KEGG: varicella-zoster virus vaccine live (Oka-Merck) strain \n",
      "\n",
      "No KEGG: picosulfurate \n",
      "\n",
      "No KEGG: L1 protein, human papillomavirus type 18 vaccine \n",
      "\n",
      "No KEGG: L1 protein, human papillomavirus type 16 vaccine \n",
      "\n",
      "No KEGG: herbal drugs \n",
      "\n",
      "No KEGG: Serenoa repens whole extract \n",
      "\n",
      "No KEGG: varicella-zoster virus vaccine live (Oka-Merck) strain \n",
      "\n",
      "No KEGG: certoparin \n",
      "\n",
      "No KEGG: heavy mineral oil \n",
      "\n",
      "No KEGG: iron \n",
      "\n",
      "No KEGG: barley extract \n",
      "\n",
      "No KEGG: iron \n",
      "\n",
      "No KEGG: MULTIVITAMINS \n",
      "\n",
      "6293\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "\n",
    "# update dictionary with info from KEGG API requests\n",
    "# copy for testing\n",
    "\n",
    "results_dict1 = copy.deepcopy(results_dict)\n",
    "def FAERS_standard_get_KEGG_info():\n",
    "    dcount = 0\n",
    "    kegg_find_results = 0\n",
    "    kegg_get_results = 0\n",
    "    for reportID in results_dict1:\n",
    "        for drug in results_dict1[reportID]['drugs']:\n",
    "            dcount += 1\n",
    "            if type(drug['KEGG']) == dict:\n",
    "                a = drug['KEGG'].copy()\n",
    "            else:\n",
    "                a = drug['KEGG']\n",
    "\n",
    "            # fix for \"ibrutinib\"\n",
    "            if drug['drug_name'] == 'ibrutinib':\n",
    "                kegg_get_results = KEGG_get_query('https://rest.kegg.jp/get/dr:D03936')\n",
    "                a['get_URL'] = 'https://rest.kegg.jp/get/dr:D03936'\n",
    "                a['D_number'] = 'D03936'\n",
    "                a['Target'] = kegg_get_results[0]\n",
    "                a['Pathway'] = kegg_get_results[1]\n",
    "                a['Classes'] = kegg_get_results[2]\n",
    "                drug['KEGG'] = a\n",
    "                continue\n",
    "\n",
    "            # fix for \"Streptococcus pneumoniae\" vaccine\n",
    "            if drug['drug_name'].startswith('Streptococcus pneumoniae'):\n",
    "                kegg_get_results = KEGG_get_query('https://rest.kegg.jp/get/dr:D10455')\n",
    "                a['get_URL'] = 'https://rest.kegg.jp/get/dr:D10455'\n",
    "                a['D_number'] = 'D10455'\n",
    "                a['Target'] = kegg_get_results[0]\n",
    "                a['Pathway'] = kegg_get_results[1]\n",
    "                a['Classes'] = kegg_get_results[2]\n",
    "                drug['KEGG'] = a\n",
    "                continue\n",
    "\n",
    "            # fix for \"insulin, regular, human\"\n",
    "            if drug['drug_name'] == 'insulin, regular, human':\n",
    "                kegg_find_results = KEGG_find_query('insulin human')\n",
    "                kegg_get_results = KEGG_get_query(kegg_find_results[1])\n",
    "                a['get_URL'] = kegg_find_results[1]\n",
    "                a['D_number'] = kegg_find_results[2]\n",
    "                a['Target'] = kegg_get_results[0]\n",
    "                a['Pathway'] = kegg_get_results[1]\n",
    "                a['Classes'] = kegg_get_results[2]\n",
    "                drug['KEGG'] = a\n",
    "                continue\n",
    "\n",
    "            # fix for Ursodiol\n",
    "            if drug['drug_name'] == 'ursodeoxycholate':\n",
    "                kegg_find_results = KEGG_find_query('Ursodiol')\n",
    "                kegg_get_results = KEGG_get_query(kegg_find_results[1])\n",
    "                a['get_URL'] = kegg_find_results[1]\n",
    "                a['D_number'] = kegg_find_results[2]\n",
    "                a['Target'] = kegg_get_results[0]\n",
    "                a['Pathway'] = kegg_get_results[1]\n",
    "                a['Classes'] = kegg_get_results[2]\n",
    "                drug['KEGG'] = a\n",
    "                continue\n",
    "\n",
    "\n",
    "            # try with original RxNorm drug name\n",
    "            try:\n",
    "                kegg_find_results = KEGG_find_query(drug['drug_name'])\n",
    "                kegg_get_results = KEGG_get_query(kegg_find_results[1])\n",
    "                a['get_URL'] = kegg_find_results[1]\n",
    "                a['D_number'] = kegg_find_results[2]\n",
    "                a['Target'] = kegg_get_results[0]\n",
    "                a['Pathway'] = kegg_get_results[1]\n",
    "                a['Classes'] = kegg_get_results[2]\n",
    "                drug['KEGG'] = a\n",
    "                continue\n",
    "\n",
    "            except:  \n",
    "                #print(\"\\ncatch 0!\", drug['drug_name'])\n",
    "                pass\n",
    "                #print(\"case id:\", reportID)\n",
    "                #print(KEGG_find_base + drug['drug_name'])\n",
    "                #print(\"concept id:\", drug['drug_concept_id'])\n",
    "\n",
    "            # try removing unnecessary trailing s\n",
    "            if drug['drug_name'][-1] == 's':\n",
    "                try:\n",
    "                    fix1 = drug['drug_name']\n",
    "                    fix1 = fix1[:-1]\n",
    "                    #print(fix1)\n",
    "                    kegg_find_results = KEGG_find_query(fix1)\n",
    "                    kegg_get_results = KEGG_get_query(kegg_find_results[1])\n",
    "                    a['get_URL'] = kegg_find_results[1]\n",
    "                    a['D_number'] = kegg_find_results[2]\n",
    "                    a['Target'] = kegg_get_results[0]\n",
    "                    a['Pathway'] = kegg_get_results[1]\n",
    "                    a['Classes'] = kegg_get_results[2]\n",
    "                    drug['KEGG'] = a\n",
    "                    #print(\"fixed by removing s:\", fix1)\n",
    "                    continue\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            # try fix for drugs that end with product\n",
    "            if drug['drug_name'].strip(\" \").endswith(\"product\"):\n",
    "                try:\n",
    "                    fixy = drug['drug_name'].strip(\" \")\n",
    "                    fixy = fixy[:-7]\n",
    "                    kegg_find_results = KEGG_find_query(fixy[0])\n",
    "                    kegg_get_results = KEGG_get_query(kegg_find_results[1])\n",
    "                    a['get_URL'] = kegg_find_results[1]\n",
    "                    a['D_number'] = kegg_find_results[2]\n",
    "                    a['Target'] = kegg_get_results[0]\n",
    "                    a['Pathway'] = kegg_get_results[1]\n",
    "                    a['Classes'] = kegg_get_results[2]\n",
    "                    #print(\"fixed by removing ', product'\")\n",
    "                    continue\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            # try fix for drugs with hyphens\n",
    "            try:\n",
    "                fix2 = drug['drug_name'].replace(\"-\", \" \")\n",
    "                kegg_find_results = KEGG_find_query(fix2)\n",
    "                kegg_get_results = KEGG_get_query(kegg_find_results[1])\n",
    "                a['get_URL'] = kegg_find_results[1]\n",
    "                a['D_number'] = kegg_find_results[2]\n",
    "                a['Target'] = kegg_get_results[0]\n",
    "                a['Pathway'] = kegg_get_results[1]\n",
    "                a['Classes'] = kegg_get_results[2]\n",
    "                drug['KEGG'] = a\n",
    "                #print(\"fixed by removing hypen:\", fix2)\n",
    "                continue\n",
    "            except Exception as e2:\n",
    "                pass\n",
    "\n",
    "             # try fix for drugs that end with \", human\"\n",
    "            if drug['drug_name'].endswith(\", human\"):\n",
    "                try:\n",
    "                    fix3 = drug['drug_name'].split(\",\")\n",
    "                    kegg_find_results = KEGG_find_query(fix3[0])\n",
    "                    kegg_get_results = KEGG_get_query(kegg_find_results[1])\n",
    "                    a['get_URL'] = kegg_find_results[1]\n",
    "                    a['D_number'] = kegg_find_results[2]\n",
    "                    a['Target'] = kegg_get_results[0]\n",
    "                    a['Pathway'] = kegg_get_results[1]\n",
    "                    a['Classes'] = kegg_get_results[2]\n",
    "                    #print(\"fixed by removing ', human'\")\n",
    "                    continue\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                # fix for vaccines with \"innactivated\"\n",
    "                if drug['drug_name'].endswith(\", inactivated\"):\n",
    "                    try:\n",
    "                        fix3 = drug['drug_name'].split(\",\")\n",
    "                        kegg_find_results = KEGG_find_query(fix3[0])\n",
    "                        kegg_get_results = KEGG_get_query(kegg_find_results[1])\n",
    "                        a['get_URL'] = kegg_find_results[1]\n",
    "                        a['D_number'] = kegg_find_results[2]\n",
    "                        a['Target'] = kegg_get_results[0]\n",
    "                        a['Pathway'] = kegg_get_results[1]\n",
    "                        a['Classes'] = kegg_get_results[2]\n",
    "                        #print(\"fixed by removing ', inactivated'\")\n",
    "                        continue\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "            # try fix for drugs that end with \"4000\"\n",
    "            if drug['drug_name'].strip(\" \").endswith(\"4000\") :\n",
    "                try:\n",
    "                    fix3 = drug['drug_name'].strip(\" \")\n",
    "                    fix3 = fix3[:-4]\n",
    "                    kegg_find_results = KEGG_find_query(fix3[0])\n",
    "                    kegg_get_results = KEGG_get_query(kegg_find_results[1])\n",
    "                    a['get_URL'] = kegg_find_results[1]\n",
    "                    a['D_number'] = kegg_find_results[2]\n",
    "                    a['Target'] = kegg_get_results[0]\n",
    "                    a['Pathway'] = kegg_get_results[1]\n",
    "                    a['Classes'] = kegg_get_results[2]\n",
    "                    #print(\"fixed by removing '4000'\")\n",
    "                    continue\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            \n",
    "            # try fix for drugs that end with \", USP\"\n",
    "            if drug['drug_name'].strip(\" \").endswith(\", USP\") :\n",
    "                try:\n",
    "                    fix3 = drug['drug_name'].strip(\" \")\n",
    "                    fix3 = fix3[:-5]\n",
    "                    kegg_find_results = KEGG_find_query(fix3[0])\n",
    "                    kegg_get_results = KEGG_get_query(kegg_find_results[1])\n",
    "                    a['get_URL'] = kegg_find_results[1]\n",
    "                    a['D_number'] = kegg_find_results[2]\n",
    "                    a['Target'] = kegg_get_results[0]\n",
    "                    a['Pathway'] = kegg_get_results[1]\n",
    "                    a['Classes'] = kegg_get_results[2]\n",
    "                    #print(\"fixed by removing ', USP'\")\n",
    "                    continue\n",
    "                except:\n",
    "                    pass\n",
    "            print(\"No KEGG:\", drug['drug_name'], \"\\n\")\n",
    "            a = \"No entry\"\n",
    "            drug['KEGG'] = a\n",
    "    print(dcount)\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "if FAERS_std == 1:\n",
    "    FAERS_standard_get_KEGG_info()\n",
    "    #print(results_dict)\n",
    "    #print(results_dict1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# update dictionary with info from KEGG API requests\n",
    "def AEOLUS_get_KEGG_info():\n",
    "    for reportID in results_dict1:\n",
    "        for drug in results_dict1[reportID]['drugs']:\n",
    "            if type(drug['KEGG']) == dict:\n",
    "                a = drug['KEGG'].copy()\n",
    "            else:\n",
    "                a = drug['KEGG']\n",
    "            # try fixes for common problems with find request\n",
    "            try:\n",
    "                kegg_find_results = KEGG_find_query(drug['drug_name'])\n",
    "            except:\n",
    "                print(\"\\ncatch 1!\")\n",
    "                print(\"case id:\", reportID)\n",
    "                print(KEGG_find_base + drug['drug_name'])\n",
    "                print(\"concept id:\", drug['drug_concept_id'])\n",
    "                # catching exception with drugs with hyphens\n",
    "                try:\n",
    "                    # try fix for mixture drugs\n",
    "                    fix1 = drug['drug_name'].split(\" \")\n",
    "                    print(\"try2:\", KEGG_find_base + fix1[0] + \" \" + fix1[2])\n",
    "                    kegg_find_results = KEGG_find_query(fix1[0] + \" \" + fix1[2])\n",
    "                    print(kegg_find_results)\n",
    "                    print(\"fix1: \", KEGG_find_base + fix1[0] + \" \" + fix1[2])\n",
    "                except Exception as e0:\n",
    "                    print(traceback.format_exc())\n",
    "                    # try fix for drugs with hyphens\n",
    "                    try:\n",
    "                        print(\"catch 2!\")\n",
    "                        print(\"error message:\", e0)\n",
    "                        fix2 = drug['drug_name'].replace(\"-\", \" \")\n",
    "                        kegg_find_results = KEGG_find_query(fix2)\n",
    "                        print(\"fixed 2:\", fix2)\n",
    "                    except Exception as e1:\n",
    "                        print(traceback.format_exc())\n",
    "                        print(\"catch 3!\")\n",
    "                        print(\"error message:\", e1)\n",
    "                        print(\"No KEGG:\", drug['drug_name'])\n",
    "                        a = \"No entry\"\n",
    "                        drug['KEGG'] = a\n",
    "                        continue    \n",
    "            kegg_get_results = KEGG_get_query(kegg_find_results[1])\n",
    "            if type(a) == dict:\n",
    "                a['get_URL'] = kegg_find_results[1]\n",
    "                a['D_number'] = kegg_find_results[2]\n",
    "                a['Target'] = kegg_get_results[0]\n",
    "                a['Pathway'] = kegg_get_results[1]\n",
    "                a['Classes'] = kegg_get_results[2]\n",
    "                drug['KEGG'] = a\n",
    "if aeolus == 1:\n",
    "    AEOLUS_get_KEGG_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3112369"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_obj0 = open('myres.txt', 'w')\n",
    "write_obj0.close()\n",
    "results_obj0 = open('myres.txt', 'a')\n",
    "results_obj0.write(str(results_dict1))\n",
    "\n",
    "#print(results_dict1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25bed791a1aed4bb13420da74a485fcfdcafbc9ecdc61a40322d51322f2b5a38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
